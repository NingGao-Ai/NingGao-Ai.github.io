---
permalink: /
title: "Ning Gao 高宁"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I’m a first year master student from Beihang University(BUAA). My research interest includes Computer Vision, Reinforcement Learning and Large Language Models.

Please click the publication button to view my current articles and work.

Contact me: gaoning_ai@buaa.edu.cn / aoyama7hai@gmail.com

## Works and Publications

### Reinforcement Learning & LLMs

**基于价值对齐的离线强化学习**
**Value-aligned Behavior Cloning for Offline Reinforcement Learning via Bi-level Optimization** [ [PDF] ](/files/ICLR2025_OfflineRL.pdf)
* **Conference:** ICLR 2025 Publication
* **Authors:** Xingyu Jiang, Ning Gao, Xiuhui Zhang, Hongkun Dou, Yue Deng
* **Abstract:** This article aims at the problem of the lack of value alignment process in offline reinforcement learning methods such as behavior cloning, thus, a two-layer optimization design is proposed to implement a weighted behavior cloning strategy learning process, fully utilizing the value information of offline samples.

**基于LLM与树搜索构建的奖励函数生成智能体**
**(Under Review)Reward Agent...** [ [PDF] ](/files/NeurIPS2025Review_RewardFunctionAgent.pdf)
* **Conference:** NeurIPS 2025 Under Review
* **Authors:** Anonymous (First Author)
* **Abstract:** This article addresses the difficulty of manually designing reward functions in reinforcement learning and proposes the use of an intelligent agent that combines LLM and tree search framework to achieve automatic design and optimization of reward functions. This framework further improves the quality of the generated reward function by utilizing the contextual reasoning ability brought by LLM testing and combining it with the actual performance of the generated reward function.

**LLM协助的进度奖励模型设计**
**(Under Review)Progress Reward...** [ [PDF] ](/files/NeurIPS2025Review_PRMinRLwithLLM.pdf)
* **Conference:** NeurIPS 2025 Under Review
* **Authors:** Anonymous (Second Author)
* **Abstract:** This article addresses the difficult optimization problem of long-range tasks in reinforcement learning, proposing the use of LLM's world knowledge for task planning and decomposition, further writing functions to judge subtask progress, and shaping a progress reward model to guide strategy learning, in order to improve strategy performance.

### Computer Vision (mainly Image Restoration)

**基于频率域启发的高效图像复原研究**
**Efficient Frequency-Domain Image Deraining with Contrastive Regularization** [ [PDF] ](/files/ECCV2024_Deraining.pdf)
* **Conference:** ECCV 2024 Publication
* **Authors:** Ning Gao, Xingyu Jiang, Xiuhui Zhang, Yue Deng
* **Abstract:** This article innovatively explores the aggregation and separability of frequency domain transformation for rain line noise, and relies on the global feature extraction inherent in the transformation to replace visual attention in achieving a more efficient Transformer architecture for rain removal tasks.

**When Fast Fourier Transform Meets Transformer for Image Restoration** [ [PDF] ](/files/ECCV2024_ImageRestoration.pdf)
* **Conference:** ECCV 2024 Publication
* **Authors:** Xingyu Jiang, Xiuhui Zhang, Ning Gao, Yue Deng
* **Abstract:** This article innovatively explores the prior separation of different types of degraded noise by frequency domain transformation, and uses this as an efficient feature extraction method to design an image restoration network backbone that combines frequency domain and spatial domain features.

**基于3DGS的真实水下场景重建**
**(Under Review)Spatiotemporal ...** [ [PDF] ](/files/ACMMM2025Review_Underwater3DGS.pdf)
* **Conference:** ACMMM 2025 Under Review
* **Authors:** Anonymous (Second Author)
* **Abstract:** This article proposes a coupling scheme between 3DGS and physical degradation formula for underwater 3D scene reconstruction and restoration tasks. It mainly focuses on physical parameter modeling and perceptual modeling for different noises, and uses depth geometric information training to achieve new perspective synthesis of underwater and waterless scenes.
